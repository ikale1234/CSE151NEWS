# Discussion



# Conclusion

Reflecting on this project, while the results were promising,there are areas requiring further scrutiny to ensure reproducibility on unseen data. Reassessing our first model, a bag-of-words logistic regression, we suspect that data leakage during preprocessing may have influenced predictions, as information from the test data and target variable likely guided the model’s decisions, leading to near-perfect performance. Additionally, applying TF-IDF to both the training and test sets together can cause issues, as the test data influences the term weights, effectively leaking information and inflating performance metrics. Another limitation of TF-IDF, especially in this context, is that if there is vocabulary found in the test set, but not in the training set, this would create a sparse matrix of mostly zeroes, and we need to further investigate how the model is able to generalize on unseen data.

The XGBoost model provided some insight into the importance of different features, however we wish to delve more into this to understand the reasoning behind why these features have the effects that they do. Although, unfortunately, it is likely that this model suffers from the same data leakage problem that affected the previous model, although we believe that in this instance, the data leakage had less of an impact on the model due to the nature of the features used, which were all numerical and less susceptible to being affected by leakage. Regardless, this model needs to be looked into more in order to truly assess the predictive capabilities and the ability to generalize on unseen data.

One area of improvement that we would like to address going forward is the dataset. Ideally, we would curate the dataset ourselves, obtaining a more diverse selection of news topics, from various sources, regions, and possibly even different languages. Even integrating external knowledge bases or fact-checking databases into the pipeline could strengthen the model’s ability to flag misinformation. By doing this, the model will hopefully be more well rounded, able to handle a wide variety of data, including unseen data. 

Another drawback of these models is that they are vulnerable to manipulation. If someone were to know the features which the model runs on, it would be possible to create articles that can get around detection. This highlights a limitation in simpler models such as Bag-of-Words logistic regression and XGBoost classification. To address this in the future, we would likely explore a more complex model, such as LSTMs, that can better capture the complex relationships and sequential dependencies that a simpler model couldn’t. By doing this we hope to make the model more robust and able to generalize with higher confidence. 

Finally, once everything is addressed involving the model, I can see room for enhancing the deployment potential of this model. Packaging the model into an accessible API or web application could enable anyone who wants to check the veracity of a news article. Being able to provide real-time predictions on an article, including confidence scores, would be the ultimate goal of the project.

Overall, while this project represents a step towards combating the spread of misinformation online, it is far from a definitive solution. Language being a dynamic mode of communication, evolving tactics of spreading misinformation, and the sheer complexity of human communication mean there will constantly be new challenges to address. That being said, this project has laid a foundation, and we are excited for the potential future directions we could go in refining and expanding our model. 
